{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from glob import glob\n\nmy_glob = glob('../input/data/*/images/*.png')\nimg_path = {os.path.basename(x): x for x in my_glob}\n\nprint(len(my_glob))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How did we get the balanced dataset csv file?\nOur group firstly used the sample dataset provided, where there are totally $5606$ images and $244$ classes. However, when we count the unique labels, we could see in this table that many classes only have one image, which is indeed a highly imbalanced dataset. Since images with ‘No finding’ label not only contain X-ray of a healthy chest, but also diseases that could not be detected, we ignored this class in our project and select the next 15 classes for training.\n\nTo deal with the imbalance problem, we tried a method called **class_weights**, where different classes are mapped to different weights, which are used to adjust the loss function during training. \nHowever, when we put class_weights into training process, the results shows that althought the the training loss is lower, test loss still flunctuated largely, and when looking at the confusion matrix, the model almost predicted all the x-ray images as one disease which has large amount of dataset, however, for those classes with small number of data, the model performs really bad. \n\nThen we turned back to our whole dataset, where there are $112120$ images with $836$ classes in total, which means there is enough space for us to choose our dataset. \nFor this 4-classes classification, we chose the 4 diseases 'Pneumothorax', 'Atelectasis', 'Nodule', 'Infiltration' with 1000 images per class to make the dataset balanced and generate a new csv. file."},{"metadata":{"trusted":true},"cell_type":"code","source":"xray_data = pd.read_csv('../input/4diseases/4diseases(1).csv')\nxray_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Assign labels to images"},{"metadata":{},"cell_type":"markdown","source":"To deal with this multi-label classification problem, we have two methods. First is classified each disease one by one (for each time, do a binary classification), and the second is use a long vector to represent the category.\n \nNote: For the first method, classifying diseases one by one, an assumption is made: diseases A|B (disease A combined with disease B) owns features simply added up by disease A and disease B. If the features for A|B are very different a lot from simply adding features from disease A and disease B from the medical point of view, this method can’t be adopted.\n \nOur outcome for the first method is very bad and we think this mainly due to:\n \n(1)    The unbalanced ratio between class 0 (diseases other than disease A, the one we want to detect) and class 1 (disease A)\n\n(2)    Class 0 contains lots of diseases and the features for these diseases are complex and vary a lot. So it’s hard for the machine to conclude some features that can be used to distinguish class 0 and class 1\n \nFor the second method, representing the labels using a long vector, we think it is the category per entry that works well, especially when we have a small amount of categories because category per entry can prevent machine from creating some new combination of diseases on its own. If the disease per entry are adopted, the machine would be confused by the similar features shared by different diseases and couldn’t predict correctly."},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = [ 'Pneumothorax', 'Atelectasis', 'Nodule', 'Infiltration']\nfor label in labels:\n    xray_data[label] = xray_data['Finding Labels'].map(lambda result: 1.0 if label in result else 0)\nxray_data['target_vector'] = xray_data.apply(lambda target: [target[labels].values], 1).map(lambda target: target[0])\nxray_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RGB2Gray, Image dimension adjustment & Image selection"},{"metadata":{},"cell_type":"markdown","source":"### GRB2GRAY \nAfter visualizing our data, we found that xray images are all not colorful. But each image still consists of 3 matrices, for example, one original image shape is (1024,1024,3) Professor reminded us that we can use RGB2GRAY to reduce 3 matrices to 1 matrices since the 3 matrices are the same for each image. After doing that, we can save memory and also reduce calculation quantity later. We include one example in the photo file to show there is no difference between the images before and after applying RGB2GRAY.\n\n### Image dimension adjustment\nAt the very beginning, we directly resized our images with pixel value $128*128$ without further consideration. We just thought the original image size is too large. However, professor reminded us that the resized image may loss many features since xray images include lots of details. After discussion, we made a plan on making image dimension adjustment.\n\nSince our original image dimension is $1024*1024$, which is too big, we think resizing our images might be a good idea if it would not cost losing too many features of the images. How to determine the pixel value needs a rigorous process. \n\nFirst, we chose an example and visualized it with different sizes. The three images are contained in our photo file, named 128, 512 and 1024. Seen by eyes, we found that the image with size $128*128$ look not quite clear. It seems that the image with dimension $512*512$ do not have much difference with the image with dimension $1024*1024$.\n\nWe have already used our eyes to make a preliminary judgement, then we need to use image with different dimensions to train our models to see the influence of the image dimension to our models' performance. Then we can make a decision which pixel value to use.\n\nThen we need to prepare dataset with different image sizes. The code below is one example process of preparing npz files (X and Y) as data to train the models later. This prepared dataset contains 4 categories diseases: 'Pneumothorax', 'Atelectasis', 'Nodule', 'Infiltration'. Each category has 1000 data and the image size is $128*128$.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\ndef proc_images():\n    x = [] # images as arrays\n    y = [] # labels of 'Pneumothorax', 'Atelectasis', 'Nodule' and 'Infiltration'\n    WIDTH = 128\n    HEIGHT = 128\n\n    for img in my_glob:\n        base = os.path.basename(img)\n        if base in xray_data2['Image Index'].values:\n            full_size_image = cv2.imread(img)\n            image_grey = cv2.cvtColor(full_size_image, cv2.COLOR_BGR2GRAY)\n            x.append(cv2.resize(image_grey, (WIDTH,HEIGHT), interpolation=cv2.INTER_CUBIC))\n            #x.append(full_size_image)\n            ylabel = xray_data[\"target_vector\"][xray_data[\"Image Index\"] == base].values\n            y.append(ylabel)\n        else:\n            continue\n    return x,y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We successfully prepare dataset with image size $128*128$ and $512*512$. However, kaggle warned us that our notebook tried to allocate more memory than is availiable when we try to prepare dataset with image size $1024*1024$ even though we only tend to contain totally 1000 images in the dataset. Since we also need to guarantee enough data in each category, we decide to give up the dataset with original image size due to equipment constraint.\n\nThen we use the two datasets to train our own model respectively. When we do 2 categories classification, as the confusion matrices shown on PPT page 20, the dataset with image size $512*512$ performs better than the dataset with image size $128*128$. \nHowever, when we do 3 categories classification and we want to use the dataset with image size $512*512$ to train more complex models, Resource Exhausted Error occurred! OOM killer killed our training process. We tried three ways to fight with OOM killer, but considering memory cost, time cost and equipment constraint, we finally decided to use the dataset with image size $128*128$ and tried our best to make our model perform well."},{"metadata":{},"cell_type":"markdown","source":"# Turn png to npz."},{"metadata":{"trusted":true},"cell_type":"code","source":"x,y = proc_images()\nx=np.array(x)\ny=np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#np.savez(\"x4000128\", x)\n#np.savez(\"y4000128\", y)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}